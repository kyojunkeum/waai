
services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    # GPU 설정: nvidia-container-toolkit 설치되어 있어야 동작
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_KEEP_ALIVE=5m
    networks:
      - waai-net
    restart: unless-stopped

  mcp-filesystem:
    build: ./mcp-filesystem
    container_name: mcp-filesystem
    environment:
      DIARY_ROOT: "/data/diary"
      IDEAS_ROOT: "/data/ideas"
      WEB_RESEARCH_ROOT: "/data/web_research"
      WORKS_ROOT: "/data/works"
      BIBLE_ROOT: "/data/bible"
    volumes:
      - ./data/diary:/data/diary
      - ./data/ideas:/data/ideas
      - ./data/web_research:/data/web_research
      - ./data/works:/data/works
      - ./data/bible:/data/bible
    networks:
      - waai-net
    restart: unless-stopped

  mcp-bridge:
    build: ./mcp-bridge
    container_name: mcp-bridge
    environment:
      DIARY_ROOT: "/data/diary"
      IDEAS_ROOT: "/data/ideas"
      WEB_RESEARCH_ROOT: "/data/web_research"
      WORKS_ROOT: "/data/works"
      BIBLE_ROOT: "/data/bible"
      LLM_BACKEND: "ollama"
      OLLAMA_URL: "http://ollama:11434"
      MODEL_NAME: "qwen2:7b"

      # openai 용
      # OPENAI_BASE_URL: "https://api.openai.com/v1"
      # OPENAI_API_KEY: "..."
      # OPENAI_MODEL: "gpt-4.1-mini"

    volumes:
      - ./data/diary:/data/diary
      - ./data/ideas:/data/ideas
      - ./data/web_research:/data/web_research
      - ./data/works:/data/works
      - ./data/bible:/data/bible
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://mcp-bridge:7002/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s
    networks:
      - waai-net
    restart: unless-stopped

  mcp-playwright:
    build: ./mcp-playwright
    container_name: mcp-playwright
    environment:
      - OUTPUT_DIR=/home/witness/memory/webresearch
      - HEADLESS=1
    volumes:
      - /home/witness/memory/webresearch:/home/witness/memory/webresearch
    networks:
      - waai-net
    restart: unless-stopped

  waai-backend:
    build: ./waai-backend
    container_name: waai-backend
    ports:
      - "8000:8000"
    environment:
      OLLAMA_URL: "http://ollama:11434"
      #MODEL_NAME: "llama3.1"
      MODEL_NAME: "qwen2:7b"
      OUTPUT_ROOT: "/data/outputs"
      CRITIQUE_OBJECTS_ROOT: "/data/critique/objects"
      CRITIQUE_RESULTS_ROOT: "/data/critique/results"
      CRITIQUE_CRITERIA_PATH: "/data/critique/criteria/합평기준규칙.md"
      DIARY_ROOT: "/data/diary"
      IDEAS_ROOT: "/data/ideas"
      WEB_RESEARCH_ROOT: "/data/web_research"
      WEBRESEARCH_OUT_DIR: "/memory/webresearch"
      WORKS_ROOT: "/data/works"
      BIBLE_ROOT: "/data/bible"
      PLAYWRIGHT_MCP_URL: "http://mcp-playwright:7003"
    volumes:
      - ./data/outputs:/data/outputs
      - ./data/diary:/data/diary
      - ./data/ideas:/data/ideas
      - ./data/web_research:/data/web_research
      - ./data/works:/data/works
      - ./data/bible:/data/bible
      - ./data/critique:/data/critique
      - /home/witness/memory/webresearch:/memory/webresearch
    depends_on:
      - ollama
      - mcp-filesystem
      - mcp-bridge
      - mcp-playwright
    healthcheck:
      test: ["CMD", "curl", "-f", "http://waai-backend:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s
    networks:
      - waai-net
    restart: unless-stopped

  data-format-bot:
    build: ./data-format-bot
    container_name: data-format-bot
    environment:
      - LLM_API_URL=http://waai-backend:8000/api/diary/format
      - DATA_REFORMAT_URL=http://waai-backend:8000/api/data/reformat-md
      - MULTI_BASE_INPUT=/home/witness/memory
      - MULTI_BASE_OUTPUT=/home/witness/waai/data
      - IGNORE_PROCESSED=true
    volumes:
      - /home/witness/memory/diary:/input
      - ./data/diary:/output
      - /home/witness/memory:/home/witness/memory
      - ./data:/home/witness/waai/data
    depends_on:
      - waai-backend
    networks:
      - waai-net
    restart: unless-stopped

  waai-monitor:
    build: ./monitor
    container_name: waai-monitor
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]
    environment:
      - TARGET_URL=http://waai-backend:8000/health
      - MCP_HEALTH=http://mcp-bridge:7002/health
      - MCP_FS_HEALTH=http://mcp-filesystem:7001/health
      - DIARY_BOT_HEALTH=http://data-format-bot:8001/health
      - INTERVAL=60
      - CPU_THRESHOLD=80
      - GPU_THRESHOLD=80
      - DIARY_DIR=/waai/data/diary
    depends_on:
      - waai-backend
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/diary:/waai/data/diary:ro
    networks:
      - waai-net
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    restart: unless-stopped
    environment:
      OLLAMA_BASE_URL: "http://ollama:11434"
      ENABLE_CUSTOM_TOOLS: "1"
    depends_on:
      - ollama
    ports:
      - "3000:8080"
    networks:
      - waai-net
    volumes:
      - openwebui-data:/app/backend/data

networks:
  waai-net:

volumes:
  ollama-data:
  openwebui-data:
